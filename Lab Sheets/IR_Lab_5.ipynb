{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Information Retrieval CSF469**\n",
        "##Lab Session - 5\n",
        "## Date - 23/02/2024\n",
        "##<font color ='GREEN'>Marks: 10</font>\n",
        "In this lab session, we implement vector-based query processing approach in which both the documents and queries are converted into vector forms. Then, a similarity based metric such as cosine similarity can be used to find the relevant documents.\n",
        "\n",
        "## Students have to write their code in blank spaces marked under <font color = \"RED\">TO-DO</font> section\n",
        "\n",
        "### After attempting the lab sheet, please rename the file as \"NAME_ID.ipynb\" and then upload it on canvas"
      ],
      "metadata": {
        "id": "ByCxbJJlONuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task is to implement vector based query processing approach. Students need to first change each text document into tfidf and store it as a matrix. Then, change query also into a vector of same size of vector as of a document. Then use a similarity metric to get the relevant documents."
      ],
      "metadata": {
        "id": "4RDE6BLZYAcF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWvkOVVtHbdi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/IRdata.csv')\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "metadata": {
        "id": "KIzjTQXJIigP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "RaTWAM6jIw4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news = dataset.iloc[:, 0]\n",
        "df_labels = dataset.iloc[:, -1]"
      ],
      "metadata": {
        "id": "bot6k8D3IzEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_news)\n",
        "df_labels = df_labels.to_frame()\n",
        "print(df_labels)"
      ],
      "metadata": {
        "id": "mhpjMLQ8JOrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Removing stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "    # Joining tokens back to sentence\n",
        "    preprocessed_text = ' '.join(stemmed_tokens)\n",
        "    return preprocessed_text"
      ],
      "metadata": {
        "id": "FxL7-xlrDlHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color = \"RED\">TO-DO</font> Implement code for converting text into TFIDF vectors.\n",
        "\n",
        "### NOTE: The size of vector for both documents and query should be same."
      ],
      "metadata": {
        "id": "w_HqeCw6YWtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class CustomTFIDFVectorizer:\n",
        "    def __init__(self):\n",
        "        self.word_idf = {}\n",
        "        self.vocab_size = 0\n",
        "\n",
        "    def fit_transform(self, documents):\n",
        "        ### write your code here for generating vector of documents\n",
        "\n",
        "        return tfidf_matrix\n",
        "\n",
        "    def transform(self, query_text, max_length=None):\n",
        "        ### write your code here for generating vector of query\n",
        "        return query_vector"
      ],
      "metadata": {
        "id": "a3nowVN1UEDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess documents\n",
        "preprocessed_documents = [preprocess_text(doc) for doc in df_news]"
      ],
      "metadata": {
        "id": "dnzwXRYCMLQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and fit the TF-IDF vectorizer\n",
        "vectorizer = CustomTFIDFVectorizer()\n",
        "\n",
        "# Fit and transform documents\n",
        "tfidf_matrix = vectorizer.fit_transform(preprocessed_documents)\n",
        "print(tfidf_matrix.shape)"
      ],
      "metadata": {
        "id": "_SftaM4SVghh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd606ce7-42d5-4e01-cb28-10ff01f6732d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(162, 611)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color = \"RED\">TO-DO</font>"
      ],
      "metadata": {
        "id": "uAzgC9QnYioc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## print the result for these queries\n",
        "query1 = \"Titagarh shares at 10%\"\n",
        "\n",
        "query2 = \"small cap company shares\"\n",
        "\n",
        "query3 = \"rail systems launch repayment\""
      ],
      "metadata": {
        "id": "aOK82EFJsvuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query processing\n",
        "query = \"multi bagger defence shares  \"\n",
        "preprocessed_query = preprocess_text(query)\n",
        "query_vector = (vectorizer.transform([preprocessed_query])).reshape(1,-1)\n",
        "# print(query_vector.shape)"
      ],
      "metadata": {
        "id": "P53Kh6osuffA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating cosine similarity between query and documents\n",
        "similarity_scores = cosine_similarity(________, ________)\n",
        "\n",
        "# Retrieving most similar five documents\n",
        "top_docs = ___________________________"
      ],
      "metadata": {
        "id": "HEJZMZgTMOn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c238e3b4-a432-45c2-c84b-835f458eb9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 611)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the top 5 most similar documents\n",
        "print(\"Top 5 most similar documents:\")\n",
        "for i, idx in enumerate(top_docs):\n",
        "    print(f\"{i+1}. Document {idx}: {df_news[idx]}\")"
      ],
      "metadata": {
        "id": "0oBjbnmiP8rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53095c8-7c33-428c-b964-c0c51aad2180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most similar documents:\n",
            "1. Document 1: 480% Returns From 1-Year Low: Multibagger Defence Stock Less Than Rs 10 Away From New High; Co Wins Big Order - Goodreturns\n",
            "2. Document 161: Titagarh Rail Share Price: Stock at record high after HSBC projects 35% upside - CNBCTV18\n",
            "3. Document 50: Stocks to watch on June 12, 2023 - BusinessLine\n",
            "4. Document 58: Avantel secures order worth Rs11.28 crore from Indian Navy - Indiainfoline\n",
            "5. Document 57: Avantel Ltd Share Price Today, Stock Price BSE - Business Today\n"
          ]
        }
      ]
    }
  ]
}