{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Information Retrieval CSF469**\n",
        "##Lab Session - 3\n",
        "## Date - 07/02/2024\n",
        "##<font color ='GREEN'>Marks: 10</font>\n",
        "In this lab session, we implement label sensitive boolean query retrivel.\n",
        "\n",
        "## Students have to write their code in blank spaces marked under <font color = \"RED\">TO-DO</font> section\n",
        "\n",
        "### After attempting the lab sheet, please rename the file as \"NAME_ID.ipynb\" and then upload it on canvas"
      ],
      "metadata": {
        "id": "ByCxbJJlONuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are given documents relating to two companies, A and B. You are required to upgrade the standard boolean retrieval system to improve the accuracy of retrieving documents given the labels that if they belong to the company A or B. For eg. if the query consists of the name ‘A’, the query should only return documents belonging to company A even if some documents of company B also match the full query."
      ],
      "metadata": {
        "id": "SeHqP33uWCOk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWvkOVVtHbdi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('IRdata.csv')\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "metadata": {
        "id": "KIzjTQXJIigP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaTWAM6jIw4f",
        "outputId": "04c34ed9-d223-4c25-dcec-70571730970b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 title     label\n",
            "0    Avantel Limited Announces Resignation of Ebv R...   Avantel\n",
            "1    480% Returns From 1-Year Low: Multibagger Defe...   Avantel\n",
            "2    Multibagger defence stock rises 5% on Rs 68 cr...   Avantel\n",
            "3    Avantel Ltd receives order worth Rs. 67.92 cro...   Avantel\n",
            "4    Rs 11 to Rs 129: This defence stock turned int...   Avantel\n",
            "..                                                 ...       ...\n",
            "157  Titagarh Rail Systems rolls out new diving sup...  Titagarh\n",
            "158  Titagarh Rail shares fall 10% from record high...  Titagarh\n",
            "159  Rs 49 to Rs 813: This railway stock turned int...  Titagarh\n",
            "160  Škoda Group secures €732m contract with Trenit...  Titagarh\n",
            "161  Titagarh Rail Share Price: Stock at record hig...  Titagarh\n",
            "\n",
            "[162 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_news = dataset.iloc[:, 0]\n",
        "df_labels = dataset.iloc[:, -1]"
      ],
      "metadata": {
        "id": "bot6k8D3IzEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_news)\n",
        "df_labels = df_labels.to_frame()\n",
        "print(df_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhpjMLQ8JOrs",
        "outputId": "87269b67-749f-4c2f-9378-c010c6822cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      Avantel Limited Announces Resignation of Ebv R...\n",
            "1      480% Returns From 1-Year Low: Multibagger Defe...\n",
            "2      Multibagger defence stock rises 5% on Rs 68 cr...\n",
            "3      Avantel Ltd receives order worth Rs. 67.92 cro...\n",
            "4      Rs 11 to Rs 129: This defence stock turned int...\n",
            "                             ...                        \n",
            "157    Titagarh Rail Systems rolls out new diving sup...\n",
            "158    Titagarh Rail shares fall 10% from record high...\n",
            "159    Rs 49 to Rs 813: This railway stock turned int...\n",
            "160    Škoda Group secures €732m contract with Trenit...\n",
            "161    Titagarh Rail Share Price: Stock at record hig...\n",
            "Name: title, Length: 162, dtype: object\n",
            "        label\n",
            "0     Avantel\n",
            "1     Avantel\n",
            "2     Avantel\n",
            "3     Avantel\n",
            "4     Avantel\n",
            "..        ...\n",
            "157  Titagarh\n",
            "158  Titagarh\n",
            "159  Titagarh\n",
            "160  Titagarh\n",
            "161  Titagarh\n",
            "\n",
            "[162 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string"
      ],
      "metadata": {
        "id": "EgiOgbtjJQ9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIU_kYq1J5Qv",
        "outputId": "4686c6a8-33a5-4578-dd64-db5b22794f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "uDz1fF37JpKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    tokens = [word.lower() for word in tokens if word.isalnum()]\n",
        "\n",
        "    tokens = [word for word in tokens if word not in stop_words]#TO-DO\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "kDBu3WnIJ0SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = df_news.apply(preprocess_text)"
      ],
      "metadata": {
        "id": "gcv6eJHYKCer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(processed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuvJ3FV6KGau",
        "outputId": "3ef13ce4-7a4f-43a5-b896-51adfbd54514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      [avantel, limited, announces, resignation, ebv...\n",
            "1      [480, returns, low, multibagger, defence, stoc...\n",
            "2      [multibagger, defence, stock, rises, 5, rs, 68...\n",
            "3      [avantel, ltd, receives, order, worth, rs, cro...\n",
            "4      [rs, 11, rs, 129, defence, stock, turned, mult...\n",
            "                             ...                        \n",
            "157    [titagarh, rail, systems, rolls, new, diving, ...\n",
            "158    [titagarh, rail, shares, fall, 10, record, hig...\n",
            "159    [rs, 49, rs, 813, railway, stock, turned, mult...\n",
            "160    [škoda, group, secures, contract, trenitalia, ...\n",
            "161    [titagarh, rail, share, price, stock, record, ...\n",
            "Name: title, Length: 162, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the inverted index dictionary\n",
        "inverted_index = {}\n",
        "\n",
        "#to-do\n",
        "# Iterate through each document and its processed tokens\n",
        "for doc_id, tokens in enumerate(processed_data):\n",
        "    for token in tokens:\n",
        "        # If the token is not already in the dictionary, add it\n",
        "        if token not in inverted_index:\n",
        "            inverted_index[token] = set()\n",
        "\n",
        "        # Add the document ID to the set of documents for this token\n",
        "        inverted_index[token].add(doc_id)"
      ],
      "metadata": {
        "id": "ghADAJ0RKITz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, doc_ids in inverted_index.items():\n",
        "    print(f\"{word}: {list(doc_ids)}\")"
      ],
      "metadata": {
        "id": "hKN9rKaYL_fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def boolean_query(query, inverted_index, df_news):\n",
        "    # Tokenize the query into words and operators\n",
        "    query_parts = query.lower().split()\n",
        "\n",
        "    # Separate words and operators\n",
        "    # words = [token for token in query_parts if token not in [\"and\", \"or\"]]\n",
        "    words = preprocess_text(query)\n",
        "    operators = [token for token in query_parts if token in [\"and\", \"or\"]]\n",
        "\n",
        "    #to-do\n",
        "    #sample queries, 1) Avantel and order or book, 2) Titagarh and international or business or client, 3) findout the internation clients of company avantel\n",
        "    #query optimization\n",
        "    #Check if the query is well-formed\n",
        "\n",
        "    if not words or len(words) - 1 != len(operators):\n",
        "        return \"Invalid query format.\"\n",
        "\n",
        "    # Initialize result with the document set of the first word\n",
        "    # Assuming words are already preprocessed\n",
        "    result_set = set(inverted_index.get(words[0], []))\n",
        "\n",
        "\n",
        "    #todo iterate\n",
        "    # Iterate over the words and apply boolean operations\n",
        "    for i, operator in enumerate(operators):\n",
        "        next_word_docs = set(inverted_index.get(words[i + 1], []))\n",
        "\n",
        "        if operator == \"and\":\n",
        "            result_set &= next_word_docs\n",
        "        elif operator == \"or\":\n",
        "            result_set |= next_word_docs\n",
        "\n",
        "    return result_set\n",
        "    # return result_set"
      ],
      "metadata": {
        "id": "vHRBCEU9MBkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color = \"RED\">TO-DO</font> (10 marks)"
      ],
      "metadata": {
        "id": "q3eWFEgKmwab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_enhanced_boolean_query(query, inverted_index, df_news, df_labels):\n",
        "    # Convert query to lower case and split into components\n",
        "    query_parts = query.lower().split()\n",
        "\n",
        "    # Using the fucntion defined above, implement the label specific query retrieval system.\n",
        "    ___________\n",
        "    ___________\n",
        "    ___________\n",
        "    ___________\n",
        "    return result_set"
      ],
      "metadata": {
        "id": "M_54NE4NyTiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"Enter a boolean query with optional labels (e.g., 'word1 AND word2 OR avantel word3'): \")\n",
        "resulting_set = label_enhanced_boolean_query(query, inverted_index, df_news, df_labels)\n",
        "print(f\"Documents satisfying '{query}':\\n{resulting_set}\")"
      ],
      "metadata": {
        "id": "8lX0p1TfPf4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b8adaf-f855-4f29-c9b4-531192844880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a boolean query with optional labels (e.g., 'word1 AND word2 OR avantel word3'): vantel and order or book\n",
            "['vantel', 'and', 'order', 'or', 'book']\n",
            "['vantel', 'order', 'book']\n",
            "Documents satisfying 'vantel and order or book':\n",
            "Series([], Name: title, dtype: object)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the results of following queries.\n",
        "\n",
        "Query1: avantel or share or defence\n",
        "\n",
        "Query2: crore or sales and titagarh\n"
      ],
      "metadata": {
        "id": "KF1nIvBdYz_J"
      }
    }
  ]
}